<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Optimization in Machine Learning (Fall 2023)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Optimization in Machine Learning (Fall 2023)</h1>
</div>
<p><b>Lecture Information</b><br />
Wed 10:50-12:15 at Tian Jiabing Building 128<br /><br />
<b>Grading</b><br />
Your grade will be determined by assignments (50%), a project (40%) and participance (10%).<br /><br /></p>
<p><b>Teaching Staffs</b><br /></p>
<ul>
<li><p>Instructor: <a href="https://chengchen8.github.io">Cheng Chen</a>, 304 Math Building, chchen@sei.ecnu.edu.cn</p>
</li>
<li><p>Teaching Asistant: Ziqi Yao, 51265902073@stu.ecnu.edu.cn </p>
</li>
</ul>
<p><b>Schedule</b><br /></p>
<table id="optml2023schedule">
<tr class="r1"><td class="c1">Date </td><td class="c2"> Topic </td><td class="c3"> Material </td><td class="c4"> Homework </td></tr>
<tr class="r2"><td class="c1">9.20. </td><td class="c2"> Introduction; Basic mathematics </td><td class="c3"> <a href="optml2023/OptML_01.pdf">slides</a> </td><td class="c4"> <a href="optml2023/OptML_hw1.pdf">hw</a>, <a href="optml2023/OptML_sol1.pdf">sol</a> </td></tr>
<tr class="r3"><td class="c1">9.27. </td><td class="c2"> Convex sets; Convex functions </td><td class="c3"> <a href="optml2023/OptML_02.pdf">slides</a>, <a href="optml2023/Notes_L2.pdf">notes</a> </td><td class="c4"> <a href="optml2023/OptML_hw2.pdf">hw</a>, <a href="optml2023/OptML_sol2.pdf">sol</a> </td></tr>
<tr class="r4"><td class="c1">10.11. </td><td class="c2"> Smooth &amp; Strongly convex; Gradient descent </td><td class="c3"> <a href="optml2023/OptML_03.pdf">slides</a> </td><td class="c4"> <a href="optml2023/OptML_hw3.pdf">hw</a>, <a href="optml2023/OptML_sol3.pdf">sol</a> </td></tr>
<tr class="r5"><td class="c1">10.18. </td><td class="c2"> More on gradient descent </td><td class="c3">  <a href="optml2023/OptML_04.pdf">slides</a> </td><td class="c4"> <a href="optml2023/OptML_hw4.zip">hw</a>, <a href="optml2023/OptML_sol4.zip">sol</a> </td></tr>
<tr class="r6"><td class="c1">11.1. </td><td class="c2"> Projected gradient descent; Frank-Wolfe algorithm </td><td class="c3"> <a href="optml2023/OptML_05.pdf">slides</a> </td><td class="c4"> <a href="optml2023/OptML_hw5.pdf">hw</a>, <a href="optml2023/OptML_sol5.pdf">sol</a> </td></tr>
<tr class="r7"><td class="c1">11.8. </td><td class="c2"> Subgradient; Subgradient descent </td><td class="c3">  <a href="optml2023/OptML_06.pdf">slides</a> </td><td class="c4"> <a href="optml2023/OptML_hw6.pdf">hw</a> 
</td></tr></table>
</div>
</body>
</html>
